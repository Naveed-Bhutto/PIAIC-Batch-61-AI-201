{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8DcVfZPv+3z0g6k0nIA+X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naveed-Bhutto/PIAIC-Batch-61-AI-201/blob/main/Function_calling_config.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini API: Function calling config\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb\"><img src=\"../images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "LsvaWRf6Kb4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specifying a function_calling_config allows you to control how the Gemini API acts when tools have been specified. For example, you can choose to only allow free-text output (disabling function calling), force it to choose from a subset of the functions provided in tools, or let it act automatically.\n",
        "\n",
        "This guide assumes you are already familiar with function calling. For an introduction, check out the docs."
      ],
      "metadata": {
        "id": "tiW-8T6lp1E0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eL-mQmj1lx5o"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To** run the following cell, your API key must be stored in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/gemini-api-cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
      ],
      "metadata": {
        "id": "KRms1uNTpx_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))"
      ],
      "metadata": {
        "id": "vz_JNh7_pwu5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up a model with tools\n",
        "\n",
        "This example uses 3 functions that control a simple hypothetical lighting system. Using these functions requires them to be called in a specific order. For example, you must turn the light system on before you can change color.\n",
        "\n",
        "While you can pass these directly to the model and let it try to call them correctly, specifying the `function_calling_config` gives you precise control over the functions that are available to the model."
      ],
      "metadata": {
        "id": "KLGJTUXKqLAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enable_lights():\n",
        "    \"\"\"Turn on the lighting system.\"\"\"    # Doc string == \"\"\" Description of function, for what purpose function is made\"\"\"\n",
        "    print(\"LIGHTBOT: Lights enabled.\")\n",
        "\n",
        "\n",
        "def set_light_color(rgb_hex: str):\n",
        "    \"\"\"Set the light color. Lights must be enabled for this to work.\"\"\"\n",
        "    print(f\"LIGHTBOT: Lights set to {rgb_hex}.\")\n",
        "\n",
        "\n",
        "def stop_lights():\n",
        "    \"\"\"Stop flashing lights.\"\"\"\n",
        "    print(\"LIGHTBOT: Lights turned off.\")\n",
        "\n",
        "\n",
        "light_controls = [enable_lights, set_light_color, stop_lights]\n",
        "instruction = \"\"\"You are a helpful lighting system bot. You can turn lights on and off,\n",
        "              and you can set the color. Do not perform any other tasks.\"\"\"     # This is System Function, setting persona for LLM AI model\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    \"models/gemini-1.5-pro\",\n",
        "    tools=light_controls,\n",
        "    system_instruction=instruction\n",
        ")\n",
        "\n",
        "chat = model.start_chat()"
      ],
      "metadata": {
        "id": "Q_l7qfZUqQyy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a helper function for setting function_calling_config on tool_config."
      ],
      "metadata": {
        "id": "O62DcnjDK2Yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.generativeai.types import content_types\n",
        "from collections.abc import Iterable\n",
        "\n",
        "\n",
        "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
        "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
        "    return content_types.to_tool_config(\n",
        "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
        "    )"
      ],
      "metadata": {
        "id": "nW0QsV-dK4hA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text-only mode: `NONE`\n",
        "\n",
        "If you have provided the model with tools, but do not want to use those tools for the current conversational turn, then specify `NONE` as the mode. `NONE` tells the model not to make any function calls, and will behave as though none have been provided."
      ],
      "metadata": {
        "id": "DbRbRuapLCEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"none\")\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Hello light-bot, what can you do?\", tool_config=tool_config\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "INFQIpEiLUEH",
        "outputId": "1719adfb-06b5-42a7-c505-51562a34833f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can turn lights on and off, and I can set the color of the lights.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Automatic mode: AUTO\n",
        "\n",
        "\n",
        "To allow the model to decide whether to respond in text or call specific functions, you can specify AUTO as the mode.\n"
      ],
      "metadata": {
        "id": "yOY40_StLZoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"auto\")\n",
        "\n",
        "response = chat.send_message(\"Light this place up!\", tool_config=tool_config)\n",
        "print(response.parts[0])\n",
        "chat.rewind();  # You are not actually calling the function, so remove this from the history."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "HPpV_bbkLXhW",
        "outputId": "d027b68d-18cf-4e95-a9cc-3184de42bcc6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function_call {\n",
            "  name: \"enable_lights\"\n",
            "  args {\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function-calling mode: ANY\n",
        "\n",
        "Setting the mode to ANY will force the model to make a function call. By setting allowed_function_names, the model will only choose from those functions. If it is not set, all of the functions in tools are candidates for function calling.\n",
        "\n",
        "In this example system, if the lights are already on, then the user can change color or turn the lights off."
      ],
      "metadata": {
        "id": "PgnIEpWcL-ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "available_fns = [\"set_light_color\", \"stop_lights\"]\n",
        "\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "response = chat.send_message(\"Make this place PURPLE!\", tool_config=tool_config)\n",
        "print(response.parts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Ggatg63bMLwt",
        "outputId": "32162131-268c-4a9a-927d-1db2dad77d35"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function_call {\n",
            "  name: \"set_light_color\"\n",
            "  args {\n",
            "    fields {\n",
            "      key: \"rgb_hex\"\n",
            "      value {\n",
            "        string_value: \"FF00FF\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Automatic function calling\n",
        "\n",
        "tool_config works when enabling automatic function calling too."
      ],
      "metadata": {
        "id": "pnnn5ziVMRof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "available_fns = [\"enable_lights\",\"set_light_color\", \"stop_lights\"]\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "# auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "# auto_chat.send_message(\"It's awful dark in here...\", tool_config=tool_config)"
      ],
      "metadata": {
        "id": "_4drVhUMMZtH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "response = auto_chat.send_message(\"It's awful dark in here...\", tool_config=tool_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "IzrbQp4XMeTQ",
        "outputId": "8009e28f-7c89-4cda-af32-5bed7984ebd8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIGHTBOT: Lights enabled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\"\n",
        "\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import google.generativeai as genai\n",
        "from typing import Literal\n",
        "\n",
        "genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))"
      ],
      "metadata": {
        "id": "COYSWVZvMhZW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define an API function\n",
        "Create a function that makes an API request. This function should be defined within the code of your application, but could call services or APIs outside of your application. The Gemini API does not call this function directly, so you can control how and when this function is executed through your application code. For demonstration purposes, this tutorial defines a mock API function that just returns the requested lighting values:\n",
        "\n"
      ],
      "metadata": {
        "id": "MtBuvDPMNm7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_light_values(brightness: int, color_temp: str):\n",
        "    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n",
        "\n",
        "    Args:\n",
        "        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n",
        "        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the set brightness and color temperature.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"brightness\": brightness,\n",
        "        \"colorTemperature\": color_temp\n",
        "    }"
      ],
      "metadata": {
        "id": "ZLQ8SRS4NkWw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Declare functions during model initialization\n",
        "When you want to use function calling with a model, you must declare your functions when you initialize the model object. You declare functions by setting the model's tools parameter:"
      ],
      "metadata": {
        "id": "rPdsgib6OLwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.5-flash',\n",
        "                              tools=[set_light_values])\n",
        "\n"
      ],
      "metadata": {
        "id": "iDB72sh6OEHf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate a function call\n",
        "Once you have initialized model with your function declarations, you can prompt the model with the defined function. You should use function calling using chat prompting (sendMessage()), since function calling generally benefits from having the context of previous prompts and responses."
      ],
      "metadata": {
        "id": "-QuRJug5OSN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Python SDK's ChatSession object simplifies managing chat sessions by handling the conversation history for you. You can use the enable_automatic_function_calling to have the SDK automatically call the function."
      ],
      "metadata": {
        "id": "QTMxFZLcOdoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a chat session that automatically makes suggested function calls\n",
        "chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "response = chat.send_message('Dim the lights so the room feels cozy and warm.')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "tItyUGCVOG0Q",
        "outputId": "8d04795b-a17b-4424-acd7-543de49a5372"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK. I've dimmed the lights to 30% brightness and set the color temperature to warm.  Is there anything else?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Parallel function calling\n",
        "In addition to basic function calling described above, you can also call multiple functions in a single turn. This section shows an example for how you can use parallel function calling.\n",
        "\n",
        "Define the tools."
      ],
      "metadata": {
        "id": "RTUsoa5kNvk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def power_disco_ball(power: bool) -> bool:\n",
        "    \"\"\"Powers the spinning disco ball.\"\"\"\n",
        "    print(f\"Disco ball is {'spinning!' if power else 'stopped.'}\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def start_music(energetic: bool, loud: bool, bpm: int) -> str:\n",
        "    \"\"\"Play some music matching the specified parameters.\n",
        "\n",
        "    Args:\n",
        "      energetic: Whether the music is energetic or not.\n",
        "      loud: Whether the music is loud or not.\n",
        "      bpm: The beats per minute of the music.\n",
        "\n",
        "    Returns: The name of the song being played.\n",
        "    \"\"\"\n",
        "    print(f\"Starting music! {energetic=} {loud=}, {bpm=}\")\n",
        "    return \"Never gonna give you up.\"\n",
        "\n",
        "\n",
        "def dim_lights(brightness: float) -> bool:\n",
        "    \"\"\"Dim the lights.\n",
        "\n",
        "    Args:\n",
        "      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
        "    \"\"\"\n",
        "    print(f\"Lights are now set to {brightness:.0%}\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "K0gP3TOOM5Ck"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now call the model with an instruction that could use all of the specified tools."
      ],
      "metadata": {
        "id": "WNMGuQPFO5_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model up with tools.\n",
        "house_fns = [power_disco_ball, start_music, dim_lights]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", tools=house_fns)\n",
        "\n",
        "# Call the API.\n",
        "chat = model.start_chat()\n",
        "response = chat.send_message(\"Turn this place into a party!\")\n",
        "\n",
        "# Print out each of the function calls requested from this single call.\n",
        "for part in response.parts:\n",
        "    if fn := part.function_call:\n",
        "        args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
        "        print(f\"{fn.name}({args})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "1U5CsO93M6NJ",
        "outputId": "799eb625-60f9-4bdd-da16-9f550c194d12"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "power_disco_ball(power=True)\n",
            "start_music(loud=True, energetic=True, bpm=120.0)\n",
            "dim_lights(brightness=0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each of the printed results reflects a single function call that the model has requested. To send the results back, include the responses in the same order as they were requested."
      ],
      "metadata": {
        "id": "Fg9sh8S4O_xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate the responses from the specified tools.\n",
        "responses = {\n",
        "    \"power_disco_ball\": True,\n",
        "    \"start_music\": \"Never gonna give you up.\",\n",
        "    \"dim_lights\": True,\n",
        "}\n",
        "\n",
        "# Build the response parts.\n",
        "response_parts = [\n",
        "    genai.protos.Part(function_response=genai.protos.FunctionResponse(name=fn, response={\"result\": val}))\n",
        "    for fn, val in responses.items()\n",
        "]\n",
        "\n",
        "response = chat.send_message(response_parts)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "34ZIF3UmNAR4",
        "outputId": "e635cc59-b692-4d04-d76f-970ae2bf597e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Party started!  Playing \"Never gonna give you up\" at 120 bpm.  The disco ball is spinning and the lights are dimmed to 50% brightness.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._tools.to_proto()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHoGEPWBNET4",
        "outputId": "9a7db697-3889-4794-fc9c-a36c3a22e6bb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[function_declarations {\n",
              "   name: \"power_disco_ball\"\n",
              "   description: \"Powers the spinning disco ball.\"\n",
              "   parameters {\n",
              "     type_: OBJECT\n",
              "     properties {\n",
              "       key: \"power\"\n",
              "       value {\n",
              "         type_: BOOLEAN\n",
              "       }\n",
              "     }\n",
              "     required: \"power\"\n",
              "   }\n",
              " }\n",
              " function_declarations {\n",
              "   name: \"start_music\"\n",
              "   description: \"Play some music matching the specified parameters.\\n\\n    Args:\\n      energetic: Whether the music is energetic or not.\\n      loud: Whether the music is loud or not.\\n      bpm: The beats per minute of the music.\\n\\n    Returns: The name of the song being played.\\n    \"\n",
              "   parameters {\n",
              "     type_: OBJECT\n",
              "     properties {\n",
              "       key: \"loud\"\n",
              "       value {\n",
              "         type_: BOOLEAN\n",
              "       }\n",
              "     }\n",
              "     properties {\n",
              "       key: \"energetic\"\n",
              "       value {\n",
              "         type_: BOOLEAN\n",
              "       }\n",
              "     }\n",
              "     properties {\n",
              "       key: \"bpm\"\n",
              "       value {\n",
              "         type_: INTEGER\n",
              "       }\n",
              "     }\n",
              "     required: \"energetic\"\n",
              "     required: \"loud\"\n",
              "     required: \"bpm\"\n",
              "   }\n",
              " }\n",
              " function_declarations {\n",
              "   name: \"dim_lights\"\n",
              "   description: \"Dim the lights.\\n\\n    Args:\\n      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\\n    \"\n",
              "   parameters {\n",
              "     type_: OBJECT\n",
              "     properties {\n",
              "       key: \"brightness\"\n",
              "       value {\n",
              "         type_: NUMBER\n",
              "       }\n",
              "     }\n",
              "     required: \"brightness\"\n",
              "   }\n",
              " }]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function call data type mapping\n",
        "Automatic schema extraction from Python functions doesn't work in all cases. For example: it doesn't handle cases where you describe the fields of a nested dictionary-object, but the API does support this. The API is able to describe any of the following types:"
      ],
      "metadata": {
        "id": "eicH0AL-PKG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`AllowedType = (int | float | bool | str | list['AllowedType'] | dict[str, AllowedType])`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sq6noStBPWek"
      }
    }
  ]
}